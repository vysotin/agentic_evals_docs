Subject,Solution Name,Overview,License,GitHub URL,GitHub Stars,Programming Languages,Storage Backend,OpenTelemetry Compatibility,OpenLLMetry Support,Key Features,Supported LLM Providers,Supported Frameworks,Deployment Options,Unique Differentiators,Official Website,Error
OpenLLMetry by Traceloop - open source LLM observability SDK,OpenLLMetry,"OpenLLMetry is an open-source observability solution for LLM applications. It provides a set of extensions for OpenTelemetry to trace and monitor calls to LLM providers, vector databases, and LLM frameworks.",Apache 2.0,https://github.com/traceloop/openllmetry,6.7k,"Python, TypeScript, Go, Ruby","Backend-agnostic. Integrates with various storage solutions via OpenTelemetry exporters (e.g., Jaeger, Zipkin, Prometheus, and commercial platforms).",OpenLLMetry is built on top of OpenTelemetry and uses the OpenTelemetry Protocol (OTLP) for exporting data. It extends OpenTelemetry's semantic conventions for LLM-specific data.,True,"Automatic instrumentation for LLMs, vector DBs, and frameworks, Integration with existing observability platforms, Workflow and task annotations, Extensible and customizable","OpenAI, Anthropic, Cohere, HuggingFace, Replicate, Bedrock (AWS), SageMaker (AWS), Vertex AI (GCP), Aleph Alpha, Google Generative AI (Gemini), Groq, IBM Watsonx AI, Mistral AI, Ollama, Together AI, WRITER","LangChain, LlamaIndex, Haystack, CrewAI, LangGraph, LiteLLM, OpenAI Agents, Agno, AWS Strands, Langflow","Self-hosted (with OpenTelemetry Collector), Cloud (via various observability platforms), Docker, Kubernetes","OpenLLMetry's tight integration with OpenTelemetry allows for seamless use with existing observability stacks. It offers a simple, two-line-of-code setup for quick instrumentation and is actively contributing to the standardization of LLM observability within the OpenTelemetry project.",https://www.traceloop.com/openllmetry,
OpenLIT - OpenTelemetry-native GenAI and LLM observability platform,OpenLIT,"OpenLIT is an open-source AI engineering platform that simplifies the development workflow for Generative AI and LLMs. It provides tools for experimenting with LLMs, managing prompts, handling API keys securely, and offers full-stack, OpenTelemetry-native observability for LLMs, vector databases, and GPUs with a single line of code.",Apache-2.0,https://github.com/openlit/openlit,2.1k,"Python, TypeScript, Go","ClickHouse, SQLite","OpenLIT is OpenTelemetry-native, providing SDKs for traces and metrics. It supports OTLP endpoints for sending data and is built on OpenTelemetry standards for seamless integration with existing observability stacks.",True,"Analytics Dashboard, OpenTelemetry-native Observability SDKs, Cost Tracking for Custom and Fine-Tuned Models, Exceptions Monitoring Dashboard, Prompt Management, API Keys and Secrets Management, Experiment with different LLMs, Fleet Hub for OpAMP Management","Openai, Ollama, Anthropic, Deepseek, Gpt4all, Cohere, Mistral, Github Models, Vllm, Azure Openai, Azure Ai Inference, Huggingface, Amazon Bedrock, Vertex AI, Google Ai Studio, Groq, Nvidia Nim, Xai, Elevenlabs, Ai21, Together.ai, Assembly AI, Featherless, Reka AI, OLA Krutrim, Titan ML, Sarvam AI, Prem AI","Langchain, Openai Agents, Litellm, Crewai, Llama Index, Browser Use, Pydantic, Dspy, Ag2, Haystack, Mem0, Guardrails AI, Phidata, Multion, Julep AI, Letta, Crawl4ai, Firecrawl, dynamiq, Controlflow, Swarmzero","Self-hosted, Docker, Kubernetes","OpenLIT offers a comprehensive suite of tools for the entire AI development lifecycle, from experimentation to production monitoring. Its zero-code Kubernetes observability and strong emphasis on being OpenTelemetry-native make it highly extensible and easy to integrate into existing workflows.",https://openlit.io/,
OpenInference by Arize - OpenTelemetry instrumentation for AI applications,OpenInference,OpenInference is a set of conventions and plugins that is complimentary to OpenTelemetry to enable tracing of AI applications. It's designed to provide insight into the invocation of LLMs and the surrounding application context such as retrieval from vector stores and the usage of external tools such as search engines or APIs.,Apache 2.0,https://github.com/Arize-ai/openinference,798,"Python, TypeScript, Java",Any OTEL-compatible collector,OpenInference is a set of conventions and plugins that is complimentary to OpenTelemetry. It uses OpenTelemetry Protocol (OTLP) to send traces to a compatible backend. It can be used with any OpenTelemetry-compatible backend.,True,"Tracing of AI applications, insight into LLM invocation, context from vector stores and external tools, transport and file-format agnostic","OpenAI, AWS Bedrock, MistralAI, VertexAI, Anthropic, Google GenAI, Groq","LlamaIndex, DSPy, LangChain, Guardrails, CrewAI, Haystack, liteLLM, Instructor, BeeAI, Microsoft Autogen AgentChat, PydanticAI, smolagents, Pipecat, LangChain4j, Spring AI","Self-hosted, Cloud, Docker, Kubernetes","OpenInference is a specification-driven, transport-agnostic, and community-driven standard for LLM observability that is built on top of and complements OpenTelemetry. It is not a standalone product but a set of conventions and plugins.",https://arize-ai.github.io/openinference/,
Langfuse - open source LLM engineering and observability platform,Langfuse,"Langfuse is an open-source LLM engineering platform that provides traces, evaluations, prompt management, and metrics to help developers debug and improve their LLM applications.",MIT,https://github.com/langfuse/langfuse,20.3k,"TypeScript, Python","PostgreSQL, ClickHouse, Redis/Valkey, S3/Blob Store",Langfuse can operate as an OpenTelemetry Backend to receive traces on the /api/public/otel (OTLP) endpoint. It uses HTTP/protobuf and does not support gRPC for the OpenTelemetry endpoint. Langfuse is compatible with OpenLLMetry and other OpenTelemetry-compatible instrumentation libraries.,True,"LLM Application Observability, Prompt Management, Evaluations, Datasets, LLM Playground, Comprehensive API","OpenAI, Azure OpenAI, Anthropic, Google AI Studio, Google Vertex AI, Amazon Bedrock","LangChain, LlamaIndex, Haystack, LiteLLM","Self-hosted, Docker, Kubernetes, Cloud","Langfuse's unique differentiators lie in its comprehensive, open-source nature and its focus on providing a complete LLM engineering platform. The combination of tracing, prompt management, and evaluation tools, along with its flexible deployment options and extensive integration capabilities, makes it a powerful solution for teams building complex LLM applications.",https://langfuse.com/,
Arize Phoenix - open source AI observability and evaluation platform,Arize Phoenix,"Arize Phoenix is an open-source AI observability and evaluation platform that helps users understand and improve AI applications. It provides a workflow for debugging and iteration by allowing users to send detailed logging information (traces), score outputs with evaluation tests, iterate on prompts, and optimize applications with experiments.",Elastic License 2.0,https://github.com/Arize-ai/phoenix,8.2k,"Python, TypeScript, JavaScript, Java","SQLite, PostgreSQL","Phoenix is built on top of OpenTelemetry and accepts traces over OTLP. It provides auto-instrumentation for popular frameworks, providers, and languages.",True,"Tracing, Evaluation, Prompt Engineering, Datasets & Experiments","OpenAI, Bedrock, Anthropic","LlamaIndex, LangChain, DSPy, Mastra, Vercel AI SDK","Self-hosted, Docker, Kubernetes, Cloud","Arize Phoenix is a free, open-source, and self-hostable LLM observability and evaluation tool that is built on top of OpenTelemetry, making it vendor, language, and framework agnostic. It offers a comprehensive suite of features including tracing, evaluation, prompt engineering, and datasets & experiments, all within a single platform. Its tight integration with the broader Arize ecosystem, including Arize AX for enterprise-grade AI observability, provides a clear path for users to scale their observability efforts as their needs grow.",https://phoenix.arize.com/,
Langtrace - open source OpenTelemetry-based LLM observability tool,Langtrace,"Langtrace is an open-source, Open Telemetry based end-to-end observability tool for LLM applications, providing real-time tracing, evaluations and metrics for popular LLMs, LLM frameworks, vectorDBs and more.",AGPL-3.0,https://github.com/Scale3-Labs/langtrace,1.1k,"TypeScript, Python","PostgreSQL, ClickHouse","Langtrace is built on OpenTelemetry and its traces are based on the OpenTelemetry standard. This allows for integration with existing observability stacks like Grafana, Datadog, and Honeycomb. It supports OTLP exporters.",,"Real-time tracing, evaluations, prompt management, dataset management, debugging, token and cost monitoring, latency and success rate monitoring, accuracy evaluation","Anthropic, Arch, Azure-OpenAI, Cerebras, Cohere, DeepSeek, Gemini, Groq, Mistral AI, KubeAI, Ollama, OpenAI, Perplexity, xAI","LlamaIndex, Langchain, CrewAI, DSPy, Mem0, OpenAI Agents SDK, SwarmZero, Vercel AI, LiteLLM, AWS Bedrock, Graphlit, Guardrails, Agno, Cleanlab, Neo4j GraphRAG","Self-hosted, Docker, Kubernetes, Cloud","The ability to use Langtrace with an existing observability stack without a Langtrace API key, and its focus on the three pillars of observability for LLM apps: Usage, Accuracy, and Performance.",https://www.langtrace.ai/,
Lunary - open source LLM monitoring and management platform,Lunary,"Lunary is an open-source observability platform for LLM applications. It enables developers to monitor, debug, and improve their AI-powered products by providing tools for tracing, prompt management, and performance analytics.",MIT,https://github.com/lunary-ai/abso,50,"TypeScript, Python",Not specified in documentation,"Lunary provides first-class support for OpenTelemetry, ingesting traces via a dedicated OTLP endpoint. It is compatible with various OpenTelemetry-native tools, including OpenLLMetry, OpenLIT, and Arize OpenInference.",True,"LLM Tracing, Prompt Management, Real-time Analytics, Error Detection, PII Masking, Role-Based Access Control (RBAC), Single Sign-On (SSO)","OpenAI, Anthropic, Groq, Ollama, OpenRouter, Voyage, Azure, Bedrock, Gemini, DeepSeek, Perplexity","LangChain, LlamaIndex, Haystack, CrewAI, Semantic Kernel","Self-hosted, Docker, Kubernetes, Cloud","Lunary offers a unified platform for LLM observability, prompt engineering, and analytics, with a strong focus on enterprise-grade features like security and compliance. Its native OpenTelemetry support and extensive list of supported LLM providers make it a versatile and future-proof solution.",https://lunary.ai/,
TruLens by TruEra - open source LLM evaluation and tracking,TruLens,TruLens is an open-source tool for evaluating and tracking LLM experiments and AI agents. It helps developers measure the quality and effectiveness of their applications using feedback functions.,MIT,https://github.com/truera/trulens,3k,"Python, Jupyter Notebook, TypeScript, Makefile, Shell, JavaScript","SQLite, PostgreSQL",TruLens is OpenTelemetry compatible. It can use spans emitted by non-TruLens code and other systems can use spans emitted by TruLens. It uses OTLP.,,"Evaluation and tracking of LLM experiments, Feedback Functions, RAG Triad, Honest, Harmless and Helpful Evals, Interoperable tracing with OpenTelemetry","Anthropic, Azure, Bedrock, Google, Snowflake Cortex","LangChain, LlamaIndex, LangGraph","Self-hosted, Docker",TruLens's focus on 'feedback functions' for programmatic evaluation and its 'RAG Triad' for evaluating RAG applications are unique. It is also now shepherded by Snowflake.,https://www.trulens.org/,
Evidently AI - open source ML and LLM monitoring platform,Evidently AI,"Evidently is an open-source Python library and platform to evaluate, test, and monitor ML and LLM systems, from experiments to production. It helps data scientists and ML engineers to understand and trust their models.",Apache 2.0,https://github.com/evidentlyai/evidently,7k,"Python, TypeScript","File system, SQLite, PostgreSQL, S3-compatible storage (Amazon S3, GCS, MinIO)",Evidently's tracing is based on OpenTelemetry and uses the open-source Tracely library. It can receive and process OpenTelemetry traces.,,"LLM evaluation, ML monitoring, Data drift detection, 100+ built-in metrics, Test Suites, Monitoring Dashboard, Tracing, Synthetic data generation, Dataset management, Eval orchestration, Alerting",Any LLM provider can be used as an evaluator.,"Not specified, but it can be integrated with any Python-based framework.","Self-hosted, Docker, Kubernetes, Cloud","Evidently provides a comprehensive suite of tools for both ML and LLM evaluation, including a rich set of 100+ built-in metrics and a flexible framework for creating custom evaluations. It also offers both a self-hosted open-source version and a managed cloud service.",https://www.evidentlyai.com/,
MLflow Tracing - OpenTelemetry-compatible LLM observability by Databricks,MLflow Tracing,"MLflow Tracing is a fully OpenTelemetry-compatible LLM observability solution that captures inputs, outputs, and metadata to help debug and understand application behavior.",Apache-2.0,https://github.com/mlflow/mlflow,23.6k,"Python, TypeScript, JavaScript, Java, R","SQLite, PostgreSQL, MySQL, MSSQL","MLflow Tracing is fully compatible with OpenTelemetry, allowing for integration with existing observability stacks. It can export traces from an app instrumented with OpenTelemetry to MLflow.",,"One-line auto tracing, Manual tracing SDK, Multi-threaded and async support, PII redaction, Sampling, Lightweight tracing SDK for production","OpenAI, Anthropic, Google, xAI, AWS Bedrock, Cohere, PaLM, MosaicML","LangChain, LlamaIndex, DSPy, Pydantic AI","Self-hosted, Docker, Kubernetes, Cloud","MLflow Tracing is open source, framework-agnostic, and part of an end-to-end MLOps platform with a strong open-source community.",https://mlflow.org/,
Helicone - open source AI Gateway and LLM observability platform,Helicone,"Helicone is an open-source LLM observability platform that allows developers to monitor, evaluate, and experiment with their large language models. It provides an AI Gateway to access over 100 AI models with a single API key and offers features like intelligent routing and automatic fallbacks.",Apache 2.0,https://github.com/Helicone/helicone,4.9k,"TypeScript, MDX, Python, PLpgSQL, Shell, JavaScript","Supabase (PostgreSQL), ClickHouse, Minio","Helicone supports asynchronous logging for multiple LLM platforms through OpenLLMetry. It is not explicitly stated whether it supports OTLP, but its architecture with a worker and a dedicated server for collecting logs suggests it can be configured to receive OpenTelemetry data.",True,"AI Gateway, Quick integration, Observe, Analyze, Playground, Prompt Management, Fine-tune, Enterprise Ready","OpenAI, Anthropic, Gemini, Vercel AI SDK, Azure OpenAI, Ollama, AWS Bedrock, Anyscale, TogetherAI, Hyperbolic, Groq, DeepInfra, Fireworks AI","LangChain, LlamaIndex, LangGraph, Vercel AI SDK, Semantic Kernel, CrewAI, ModelFusion, PostHog, RAGAS, Open WebUI, MetaGPT, Open Devin, Mem0 EmbedChain, Dify","Docker, Helm, Self-hosted","Helicone provides a unified API for over 100 LLM providers through its AI Gateway, simplifying the process of switching between models. It also offers a generous free tier and is enterprise-ready with SOC 2 and GDPR compliance.",https://www.helicone.ai/,
Jaeger - open source distributed tracing backend for OpenTelemetry,Jaeger,"Jaeger is an open-source, end-to-end distributed tracing system that helps developers monitor and troubleshoot transactions in complex, distributed systems. It was created by Uber Technologies and is now a graduated project of the Cloud Native Computing Foundation (CNCF).",Apache 2.0,https://github.com/jaegertracing/jaeger,22.3k,"Go, Python, Shell, Makefile, Jsonnet, Dockerfile","Elasticsearch, OpenSearch, Cassandra, Badger, Kafka, Memory","Jaeger is a customized distribution of the OpenTelemetry Collector. It can receive trace data via OTLP and supports various OpenTelemetry components like receivers, processors, and exporters. It can be used with the OpenTelemetry Collector for more advanced use cases.",,"Distributed tracing, service dependency analysis, performance monitoring, root cause analysis, adaptive sampling, post-collection data processing",Not specified,Not specified,"Self-hosted, Docker, Kubernetes, All-in-one binary","Jaeger v2 is built on the OpenTelemetry Collector framework, making it highly extensible and aligned with the OpenTelemetry project. It offers a variety of storage backends and deployment options, providing flexibility for different use cases.",https://www.jaegertracing.io/,
SigNoz - open source APM with LLM observability support,SigNoz,"SigNoz is an open-source observability platform that provides logs, traces, and metrics in a single application. It is designed as an open-source alternative to commercial APM tools like DataDog and NewRelic, offering a unified solution for monitoring and troubleshooting applications.",MIT,https://github.com/SigNoz/signoz,25.2k,"Go, TypeScript, Python, Java, JavaScript, Node.js, Ruby, Elixir, Rust, Swift, .NET, PHP",ClickHouse,SigNoz is OpenTelemetry-native and natively supports OTLP. It provides an OpenTelemetry collector to receive data in OTLP format and can be integrated with any OpenTelemetry-instrumented application.,True,"Application Performance Monitoring (APM), Distributed Tracing, Log Management, Infrastructure Monitoring, Exception Monitoring, Alerting","OpenAI, Anthropic, Amazon Bedrock, Azure OpenAI, Google Gemini, DeepSeek, Grok","LangChain, LlamaIndex, AutoGen, Crew AI, LiteLLM, Semantic Kernel, Vercel AI SDK","Self-hosted, Docker, Kubernetes, Cloud","SigNoz provides a unified platform for logs, metrics, and traces, eliminating the need for multiple tools. It is built on OpenTelemetry, preventing vendor lock-in, and uses ClickHouse as a high-performance, cost-effective storage backend for observability data.",https://signoz.io/,
Grafana Tempo - open source distributed tracing backend,Grafana Tempo,"Grafana Tempo is an open source, easy-to-use, and high-scale distributed tracing backend. It is designed to be cost-efficient, requiring only object storage to operate. Tempo is deeply integrated with Grafana, Prometheus, and Loki, and can ingest common open source tracing protocols, including Jaeger, Zipkin, and OpenTelemetry.",AGPL-3.0,https://github.com/grafana/tempo,5k,Go,"Azure, GCS, S3, local disk","Grafana Tempo's receiver layer, wire format, and storage format are all based directly on standards and code established by OpenTelemetry. It supports open standards and can receive trace data from the OpenTelemetry collector. It is compatible with Jaeger, Zipkin, Kafka, and OpenCensus as well.",True,"High-scale distributed tracing, Cost-effective, using object storage, Deep integration with Grafana, Prometheus, and Loki, Ingests common open source tracing protocols (Jaeger, Zipkin, OpenTelemetry), TraceQL for querying traces, Traces Drilldown UI for intuitive analysis","OpenAI, Anthropic, Bedrock, Cohere, Watsonx, Gemini, Mistral AI, together.ai, Ollama","LangChain, LlamaIndex","Self-hosted, Grafana Cloud, Grafana Enterprise Traces, Docker, Helm, Jsonnet","Grafana Tempo's primary differentiator is its cost-effectiveness at scale. By not indexing traces and relying on object storage, it can store a massive volume of trace data for a fraction of the cost of traditional solutions. Its deep integration with the Grafana ecosystem (Prometheus, Loki) provides a seamless observability experience.",https://grafana.com/oss/tempo/,
Uptrace - open source OpenTelemetry APM and tracing,Uptrace,"Uptrace is an open-source APM and observability platform that unifies traces, metrics, and logs. It is built on OpenTelemetry and ClickHouse and aims to provide enterprise-level observability at a lower cost than competitors like Datadog.",AGPL-3.0,https://github.com/uptrace/uptrace,4k,"Go, Vue, TypeScript, HTML, Python, Shell","PostgreSQL, ClickHouse","Uptrace is OpenTelemetry-native and supports ingestion from OpenTelemetry, Prometheus, Vector, FluentBit, and CloudWatch. It can be used as a Tempo/Prometheus datasource in Grafana.",,"Service graph, RED metrics, latency percentiles, error and log pattern analysis, alerting, single sign-on","OpenAI, Anthropic, Cohere","LangChain, LlamaIndex, Haystack","Self-hosted, Docker, Kubernetes, Cloud","Uptrace claims up to 80% cost savings compared to Datadog, offers a predictable pricing model, and is OpenTelemetry-native to avoid vendor lock-in.",https://uptrace.dev/,
